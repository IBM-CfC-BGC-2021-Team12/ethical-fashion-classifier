# Ethical Fashion Classifier

This repository contains Python scripts that

-  create ethical fashion train/test data sets,
-  train an [IBM Cloud Natural Language Classifier](https://cloud.ibm.com/catalog/services/natural-language-classifier), and
-  test the classifier.

## Requirements

To use these scripts you need

- Python 3, which you can install from python.org,
- the Python requests library,
- the NLTK library, and
- the Beautiful Soup library.

### How to install

Install Python 3 using the instructions at python.org.  Then open a command-line terminal and execute the following commands:

```
pip3 install requests
pip3 install nltk
pip3 install beautifulsoup4
```

## Creating Data Sets

Data sets are built from the web sites of human-classified ethical and unethical fashion brands, as listed on https://goodonyou.eco/most-ethical-and-sustainable-clothing-brands-from-us-and-canada/ and https://theprettyplaneteer.com/fast-fashion-brands-to-avoid/.

The `create_datasets.py` script:

- fetches each web page,
- extracts the text,
- converts letters to lower case,
- removes extra whitespace by tokenizing and then joining the list of tokes with " ",
- removes non-alphanumeric characters using a regular expression substitution, and
- writes the first 1024 characters and the appropriate `ETHICAL` or `UNETHICAL` label to the CSV data set file.

The 1024 character limit is a requirement of IBM Cloud Natural Language Classifier.

Note that the `create_datasets.py` script is written to be as understandable as possible for a beginner programmer.  It does not factor repeated code into reusable functions, uses several intermediate variables to make the process clear, does not guard against execution on module import, or use any unnecessary Python features.  Modifying this script to make it more [Pythonic](https://docs.python-guide.org/writing/style/) could be a fun project for an intermediate Pythonista.

> This repository includes data sets generated by `create_datasets.py`.  You normally wouldn't include generated code in a repository, but we include it here in case some students have trouble running the script, and to provide an example of what the data sets look like.
